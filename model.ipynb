{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "\n",
       "    margin5   margin6   margin7  margin8    ...      texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344        0    ...       0.007812          0   \n",
       "1  0.025391  0.001953  0.019531        0    ...       0.000977          0   \n",
       "2  0.003906  0.005859  0.068359        0    ...       0.154300          0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156          0          0   0.004883   \n",
       "1   0.000000   0.000977   0.023438          0          0   0.000977   \n",
       "2   0.005859   0.000977   0.007812          0          0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "\n",
       "[3 rows x 194 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'species', 'margin1', 'margin2', 'margin3', 'margin4', 'margin5',\n",
      "       'margin6', 'margin7', 'margin8',\n",
      "       ...\n",
      "       'texture55', 'texture56', 'texture57', 'texture58', 'texture59',\n",
      "       'texture60', 'texture61', 'texture62', 'texture63', 'texture64'],\n",
      "      dtype='object', length=194)\n",
      "Index(['id', 'margin1', 'margin2', 'margin3', 'margin4', 'margin5', 'margin6',\n",
      "       'margin7', 'margin8', 'margin9',\n",
      "       ...\n",
      "       'texture55', 'texture56', 'texture57', 'texture58', 'texture59',\n",
      "       'texture60', 'texture61', 'texture62', 'texture63', 'texture64'],\n",
      "      dtype='object', length=193)\n"
     ]
    }
   ],
   "source": [
    "print (train.columns)\n",
    "print (test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode(train, test):\n",
    "    le = LabelEncoder().fit(train.species) \n",
    "    labels = le.transform(train.species)           # encode species strings\n",
    "    classes = list(le.classes_)                    # save column names for submission\n",
    "    test_ids = test.id                             # save test ids for submission\n",
    "    \n",
    "    train = train.drop(['species', 'id'], axis=1)  \n",
    "    test = test.drop(['id'], axis=1)\n",
    "    \n",
    "    return train, labels, test, test_ids, classes\n",
    "\n",
    "train, labels, test, test_ids, classes = encode(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 198\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)\n",
    "print (len(y_train), len(y_test))\n",
    "\n",
    "print (len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, BaseNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_performance(y_true, X_test, model):\n",
    "    print ('Acc:', accuracy_score(y_true, model.predict(X_test)))\n",
    "    #print('F1:', f1_score(y_true, model.predict(X_test), labels=labels, average='macro'))\n",
    "    #print ('Log loss:', log_loss(y_true, model.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.954545454545\n",
      "Acc: 0.959595959596\n",
      "Acc: 0.924242424242\n",
      "Acc: 0.818181818182\n",
      "Acc: 0.474747474747\n",
      "Acc: 0.772727272727\n",
      "Acc: 0.924242424242\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=8, criterion='entropy', max_features=5)\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)    \n",
    "\n",
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)\n",
    "\n",
    "model = LogisticRegressionCV(max_iter=20000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)   \n",
    "\n",
    "model = xgb.XGBClassifier(learning_rate=0.5, max_depth=5, seed=12, gamma=0.03, subsample=2)\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)\n",
    "\n",
    "model = MultinomialNB(alpha=0.002)\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)\n",
    "\n",
    "model = BernoulliNB(alpha=0.05, binarize=0.002)\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=8,\n",
       "       param_grid={'C': [1, 10, 50, 100, 500, 1000, 2000], 'tol': [0.001, 0.0001, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit='True', scoring='log_loss',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "params = {'C':[1, 10, 50, 100, 500, 1000, 2000], 'tol': [0.001, 0.0001, 0.005]}\n",
    "log_reg = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "clf = GridSearchCV(log_reg, params, scoring='log_loss', refit='True', n_jobs=8, cv=3)\n",
    "clf.fit(X_train, y_train)  \n",
    "\n",
    "print(\"best params: \" + str(clf.best_params_))\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std(), params))\n",
    "    print(scores)\n",
    "\n",
    "log_reg = LogisticRegression(solver='newton-cg', multi_class='multinomial', C=2000, tol=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "print_performance(y_val, X_val, model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of classes 85, 99",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-b7364efd4de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/weenkus/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         raise ValueError(\"y_true and y_pred have different number of classes \"\n\u001b[1;32m-> 1565\u001b[1;33m                          \"%d, %d\" % (T.shape[1], Y.shape[1]))\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m     \u001b[1;31m# Renormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of classes 85, 99"
     ]
    }
   ],
   "source": [
    "m1 = RandomForestClassifier(n_estimators=30, random_state=42, n_jobs=8, criterion='entropy', max_features=5)\n",
    "m2 = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
    "m3 = KNeighborsClassifier(11)\n",
    "m4 = RandomForestClassifier(n_estimators=500, n_jobs=8)\n",
    "m5 = LinearDiscriminantAnalysis(solver='lsqr', tol=2)\n",
    "m6 = xgb.XGBClassifier(seed=42)\n",
    "\n",
    "model = VotingClassifier(\n",
    "    estimators=[('rf', m1), ('knn', m2), ('a', m3)], voting='soft'\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(model, cv=4, method='sigmoid')\n",
    "model.fit(X_train, y_train)\n",
    "print (log_loss(y_test, model.predict_proba(X_test)))\n",
    "print_performance(y_test, X_test, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# m1 = RandomForestClassifier(n_jobs=8)\n",
    "# m2 = LogisticRegressionCV()\n",
    "# m3 = KNeighborsClassifier()\n",
    "# m4 = LinearDiscriminantAnalysis()\n",
    "# m5 = xgb.XGBClassifier()\n",
    "\n",
    "# model = VotingClassifier(\n",
    "#     estimators=[('rf', m1), ('knn', m3), ('lda', m4), ('xgb', m5), ('logreg', m2)], voting='soft'\n",
    "# )\n",
    "\n",
    "# params = {\n",
    "#     'rf__max_features': [3, 4, 5],\n",
    "#     'rf__criterion': ['entropy', 'gini'],\n",
    "#     'rf__n_estimators': [370, 200],\n",
    "#     'logreg__max_iter': [500, 1500],\n",
    "#     'xgb__n_estimators': [200, 370],\n",
    "#     'knn__n_neighbors': [3, 6]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=params, cv=3)\n",
    "# grid = grid.fit(X_train, y_train)\n",
    "\n",
    "#model = CalibratedClassifierCV(model, cv=3, method='sigmoid')\n",
    "#model.fit(X_train, y_train)\n",
    "#print_performance(y_val, X_val, model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/weenkus/anaconda3/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/weenkus/anaconda3/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/weenkus/anaconda3/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1576</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.655793</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.005013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1577</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.004574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1579</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.006375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1580</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.005563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1583</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.005539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Acer_Capillipes  Acer_Circinatum  Acer_Mono  Acer_Opalus  \\\n",
       "589  1576         0.003383         0.655793   0.003241     0.002950   \n",
       "590  1577         0.003759         0.003782   0.003123     0.003136   \n",
       "591  1579         0.003964         0.004340   0.003841     0.003583   \n",
       "592  1580         0.005521         0.005524   0.005905     0.005385   \n",
       "593  1583         0.004366         0.004658   0.004288     0.004097   \n",
       "\n",
       "     Acer_Palmatum  Acer_Pictum  Acer_Platanoids  Acer_Rubrum  Acer_Rufinerve  \\\n",
       "589       0.003584     0.003441         0.003135     0.003415        0.013343   \n",
       "590       0.003150     0.003449         0.003183     0.004109        0.004325   \n",
       "591       0.004456     0.005025         0.003862     0.004005        0.003695   \n",
       "592       0.005336     0.005539         0.005530     0.005659        0.005081   \n",
       "593       0.004186     0.004725         0.004256     0.004466        0.004122   \n",
       "\n",
       "          ...         Salix_Fragilis  Salix_Intergra  Sorbus_Aria  \\\n",
       "589       ...               0.003277        0.002986     0.003301   \n",
       "590       ...               0.003311        0.003036     0.003352   \n",
       "591       ...               0.003986        0.003653     0.003969   \n",
       "592       ...               0.006110        0.009277     0.005225   \n",
       "593       ...               0.004394        0.004088     0.004244   \n",
       "\n",
       "     Tilia_Oliveri  Tilia_Platyphyllos  Tilia_Tomentosa  Ulmus_Bergmanniana  \\\n",
       "589       0.003479            0.003118         0.003316            0.003455   \n",
       "590       0.003800            0.005294         0.004881            0.003488   \n",
       "591       0.004279            0.003915         0.003924            0.004280   \n",
       "592       0.008075            0.005161         0.005549            0.005693   \n",
       "593       0.004616            0.004171         0.004489            0.004557   \n",
       "\n",
       "     Viburnum_Tinus  Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "589        0.002755                      0.003343         0.005013  \n",
       "590        0.002822                      0.003343         0.004574  \n",
       "591        0.003455                      0.004315         0.006375  \n",
       "592        0.006751                      0.005464         0.005563  \n",
       "593        0.003948                      0.004439         0.005539  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Test Set\n",
    "model.fit(train, labels)\n",
    "predictions = model.predict_proba(test)\n",
    "\n",
    "# Format DataFrame\n",
    "submission = pd.DataFrame(predictions, columns=classes)\n",
    "submission.insert(0, 'id', test_ids)\n",
    "submission.reset_index()\n",
    "\n",
    "# Export Submission\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
